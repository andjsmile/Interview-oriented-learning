
### 大文件查找问题

1.使用布隆过滤器bloom filter

 100亿个黑名单网页，一个url最大64B,判断网页是否在黑名单上

 64*100亿=640GB

使用布隆过滤器   m=-(n*ln(p))/(ln2)^2=  20n=25GB

               k=(ln2)*m/n=0.7*m/n=14   哈希函数的个数


2.2GB内存中20亿个整数中找到出现次数最多的数(32位的整数)

直接建立哈希表  key 4B  ,value 4B

20亿*8=16GB

可以将20亿个文件分成16个文件，则每个文件最多2亿个数

最后在16个文件的最大值中找到最大值

3.40亿个非负数找到未出现的数

如果直接建立哈希表
40亿*4B=16GB

使用bitmap  32位的无符号数
0~4294967295/8   约等于500MB

利用bitmap[index] 进行计数,记录出现的个数

4.100亿个URL中找到重复的URL，以及搜索topK问题

利用hash进行分流 ,可以分配到100台机器上
                分配到100个文件上

topK问题利用hash分流，利用小根堆实现


5.40亿个数，找到中位数

leetcode 295 找到数据流的中位数

利用优先队列来实现,  左侧是最大堆(元素是降序进行排列)
                  右侧是最小堆(元素是升序进行排列)
最大堆的最大元素  < 最小堆的最小元素

- 当内存足够的时候，采用快排的思想

• 随机选取一个数，将比它小的元素放在它左边，比它大的元素放在右边 
• 如果它恰好在中位数的位置，那么它就是中位数，直接返回 
• 如果小于它的数超过一半，那么中位数一定在左半边，递归到左边处理（还是第几大） 
• 否则中位数一定在右半边，根据左半边的元素个数计算出中位数是右半边的第几大（重新算第几大），然后递归到右半边处理

- 当内存不够的时候，采用分桶法

把所有数划分到各个小区间，把每个数映射到对应的区间里，对每个区间中数的个数进行计数，数一遍各个区间，看看中位数落在哪个区间，若够小，使用基于内存的算法，否则继续划分。
比如数是32位的，根据每个整数的二进制前5位，划分为32个桶，把数放进对应桶中。如果该桶放不下，继续划分，直至内存可以放心为止。统计每个桶中元素个数，算出中位数一定出现在哪个桶中，而且计算出是该桶中的第几大


